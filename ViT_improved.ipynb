{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11959,"sourceType":"datasetVersion","datasetId":8544},{"sourceId":13760678,"sourceType":"datasetVersion","datasetId":8756791}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"06038c28-b9d7-43a7-bc19-59de2f81fc33","cell_type":"code","source":"import random\nimport math\nimport pandas as pd\nimport numpy as np\nfrom sklearn.utils import shuffle\nimport torch\nfrom torch import cuda\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nimport torch.optim as optim\nfrom torchvision import transforms, models\nfrom tqdm import tqdm\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, SequentialLR, LinearLR\nfrom PIL import Image\nfrom torchvision.transforms import AutoAugment, AutoAugmentPolicy, RandAugment","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:01.468212Z","iopub.execute_input":"2025-11-17T04:37:01.469109Z","iopub.status.idle":"2025-11-17T04:37:01.474136Z","shell.execute_reply.started":"2025-11-17T04:37:01.469082Z","shell.execute_reply":"2025-11-17T04:37:01.473171Z"}},"outputs":[],"execution_count":17},{"id":"6dabf225-264f-46b3-9202-68963e4bf6fa","cell_type":"code","source":"device = torch.device(\"cuda\" if cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:01.791301Z","iopub.execute_input":"2025-11-17T04:37:01.791977Z","iopub.status.idle":"2025-11-17T04:37:01.796735Z","shell.execute_reply.started":"2025-11-17T04:37:01.791954Z","shell.execute_reply":"2025-11-17T04:37:01.796018Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":18},{"id":"09683768-2e2d-49e3-9385-26da9b678ddf","cell_type":"code","source":"!ls /kaggle/input/food-101/food-101/food-101/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:02.034491Z","iopub.execute_input":"2025-11-17T04:37:02.035161Z","iopub.status.idle":"2025-11-17T04:37:02.175556Z","shell.execute_reply.started":"2025-11-17T04:37:02.035138Z","shell.execute_reply":"2025-11-17T04:37:02.174624Z"}},"outputs":[{"name":"stdout","text":"images\tlicense_agreement.txt  meta  README.txt\n","output_type":"stream"}],"execution_count":19},{"id":"f4cc228d-fd75-475f-866b-ee415df70b71","cell_type":"code","source":"with open(\"/kaggle/input/food-101/food-101/food-101/meta/classes.txt\", 'r') as f:\n    classes = f.read().splitlines()","metadata":{"execution":{"iopub.status.busy":"2025-11-17T04:37:02.358458Z","iopub.execute_input":"2025-11-17T04:37:02.358740Z","iopub.status.idle":"2025-11-17T04:37:02.363449Z","shell.execute_reply.started":"2025-11-17T04:37:02.358714Z","shell.execute_reply":"2025-11-17T04:37:02.362822Z"},"trusted":true},"outputs":[],"execution_count":20},{"id":"ab525453-65bc-4dab-ba83-09d97d3e1d12","cell_type":"code","source":"class Label_encoder:\n    def __init__(self, labels):\n        self.labels = {label: idx for idx, label in enumerate(labels)}\n    def get_label(self, idx):\n        return list(self.labels.keys())[idx]\n    def get_idx(self, label):\n        return self.labels.get(label)\n\nencoder = Label_encoder(classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:03.038895Z","iopub.execute_input":"2025-11-17T04:37:03.039485Z","iopub.status.idle":"2025-11-17T04:37:03.044047Z","shell.execute_reply.started":"2025-11-17T04:37:03.039459Z","shell.execute_reply":"2025-11-17T04:37:03.043341Z"}},"outputs":[],"execution_count":21},{"id":"f60695d1-de5a-450d-bfd3-37b3c0e376d4","cell_type":"code","source":"class Food101(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = self.dataframe.path.iloc[idx]\n        image = Image.open(img_name)\n        if image.mode != 'RGB':\n            image = image.convert('RGB')\n\n        label = encoder.get_idx(self.dataframe.label.iloc[idx])\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:03.268453Z","iopub.execute_input":"2025-11-17T04:37:03.268991Z","iopub.status.idle":"2025-11-17T04:37:03.274203Z","shell.execute_reply.started":"2025-11-17T04:37:03.268971Z","shell.execute_reply":"2025-11-17T04:37:03.273277Z"}},"outputs":[],"execution_count":22},{"id":"e57500d2-6a81-4c5c-b15d-ccc338171a15","cell_type":"code","source":"def prep_df(path: str) -> pd.DataFrame:\n    with open(path, 'r') as f:\n        names = f.read().splitlines()\n    img_path = \"/kaggle/input/food-101/food-101/food-101/images/\"\n    labels = [n.split('/')[0] for n in names]\n    full_paths = [img_path + n + \".jpg\" for n in names]\n    df = pd.DataFrame({'label': labels, 'path': full_paths})\n    df = shuffle(df).reset_index(drop=True)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:03.653496Z","iopub.execute_input":"2025-11-17T04:37:03.654196Z","iopub.status.idle":"2025-11-17T04:37:03.658873Z","shell.execute_reply.started":"2025-11-17T04:37:03.654171Z","shell.execute_reply":"2025-11-17T04:37:03.658226Z"}},"outputs":[],"execution_count":23},{"id":"02358dba-3c73-45f4-aad5-011cf0052920","cell_type":"code","source":"train_imgs = prep_df('/kaggle/input/food-101/food-101/food-101/meta/train.txt')\ntest_imgs = prep_df('/kaggle/input/food-101/food-101/food-101/meta/test.txt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:05.592499Z","iopub.execute_input":"2025-11-17T04:37:05.593121Z","iopub.status.idle":"2025-11-17T04:37:05.678039Z","shell.execute_reply.started":"2025-11-17T04:37:05.593095Z","shell.execute_reply":"2025-11-17T04:37:05.677491Z"}},"outputs":[],"execution_count":24},{"id":"d6c8b463-e838-4b08-970d-806ab870c266","cell_type":"code","source":"img_size = 224\nbatch_size = 32\nbase_lr = 3e-4\nbackbone_lr = 1e-5\nweight_decay = 0.05\ntotal_epochs = 30\nwarmup_epochs = 3\nmixup_prob = 0.5\nmixup_alpha = 0.8\ncutmix_alpha = 1.0\nlabel_smoothing = 0.1\n\n\nmean = [0.485, 0.456, 0.406]\nstd  = [0.229, 0.224, 0.225]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:05.751406Z","iopub.execute_input":"2025-11-17T04:37:05.751634Z","iopub.status.idle":"2025-11-17T04:37:05.756116Z","shell.execute_reply.started":"2025-11-17T04:37:05.751618Z","shell.execute_reply":"2025-11-17T04:37:05.755367Z"}},"outputs":[],"execution_count":25},{"id":"a27f8bd3-ce0a-485f-ac39-3861fa35bf94","cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.3, 0.3, 0.2, 0.05),\n    \n    RandAugment(num_ops=2, magnitude=9), \n    transforms.ToTensor(),\n    transforms.Normalize(mean, std),\n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize(int(img_size*256/224)),\n    transforms.CenterCrop(img_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:05.915141Z","iopub.execute_input":"2025-11-17T04:37:05.915821Z","iopub.status.idle":"2025-11-17T04:37:05.920534Z","shell.execute_reply.started":"2025-11-17T04:37:05.915799Z","shell.execute_reply":"2025-11-17T04:37:05.919930Z"}},"outputs":[],"execution_count":26},{"id":"139a7f1a-3865-4a05-bf73-25a780162cb5","cell_type":"code","source":"trainset = Food101(train_imgs, transform=train_transforms)\ntrainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n\ntestset = Food101(test_imgs, transform=test_transforms)\ntestloader = DataLoader(testset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:06.111150Z","iopub.execute_input":"2025-11-17T04:37:06.111733Z","iopub.status.idle":"2025-11-17T04:37:06.130323Z","shell.execute_reply.started":"2025-11-17T04:37:06.111715Z","shell.execute_reply":"2025-11-17T04:37:06.129739Z"}},"outputs":[],"execution_count":27},{"id":"d75381b1-54b3-4157-85f5-02a0ebbe5682","cell_type":"code","source":"model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n\n# Freeze everything first\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace head (classifier)\nnum_classes = len(classes)\nin_features = model.heads.head.in_features\nmodel.heads.head = nn.Sequential(\n        nn.Linear(in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(0.4),\n        nn.Linear(512, num_classes)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:07.500682Z","iopub.execute_input":"2025-11-17T04:37:07.501313Z","iopub.status.idle":"2025-11-17T04:37:08.881330Z","shell.execute_reply.started":"2025-11-17T04:37:07.501289Z","shell.execute_reply":"2025-11-17T04:37:08.880508Z"}},"outputs":[],"execution_count":28},{"id":"5427c607-b3f8-4fd4-ac1d-680e7565d6a1","cell_type":"code","source":"unfreeze_last_n = 4\nlayers = model.encoder.layers\nif unfreeze_last_n > 0:\n    for layer in layers[-unfreeze_last_n:]:\n        for p in layer.parameters():\n            p.requires_grad = True\nfor p in model.encoder.ln.parameters():\n        p.requires_grad = True\n        \n\n# Move model to device\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:08.882445Z","iopub.execute_input":"2025-11-17T04:37:08.882719Z","iopub.status.idle":"2025-11-17T04:37:08.976191Z","shell.execute_reply.started":"2025-11-17T04:37:08.882697Z","shell.execute_reply":"2025-11-17T04:37:08.975424Z"}},"outputs":[],"execution_count":29},{"id":"eccbf3a4-5e7e-4d11-ab7a-7a323289ea4f","cell_type":"code","source":"head_params = list(model.heads.parameters())\nhead_param_ids = {id(p) for p in head_params}\n\nencoder_params = [p for p in model.parameters() if p.requires_grad and id(p) not in head_param_ids]\n\noptimizer = optim.AdamW([\n    {'params': head_params, 'lr': base_lr},\n    {'params': encoder_params, 'lr': base_lr * 0.1}\n], weight_decay=1e-4)\n# Criterion (we will use mix loss combination for mixup/cutmix)\ncriterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n\n# Scheduler: linear warmup then cosine\nscheduler = SequentialLR(\n    optimizer,\n    schedulers=[\n        LinearLR(optimizer, start_factor=0.1, total_iters=warmup_epochs),\n        CosineAnnealingLR(optimizer, T_max=max(1, total_epochs - warmup_epochs))\n    ],\n    milestones=[warmup_epochs]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:09.146262Z","iopub.execute_input":"2025-11-17T04:37:09.146541Z","iopub.status.idle":"2025-11-17T04:37:09.153537Z","shell.execute_reply.started":"2025-11-17T04:37:09.146502Z","shell.execute_reply":"2025-11-17T04:37:09.152754Z"}},"outputs":[],"execution_count":30},{"id":"b8690324-9196-4a13-bb58-7b3c92c80e3a","cell_type":"code","source":"def rand_bbox(size, lam):\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\ndef mixup_data(x, y, alpha=1.0):\n    if alpha <= 0:\n        return x, y, y, 1.0\n    lam = np.random.beta(alpha, alpha)\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(device)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef cutmix_data(x, y, alpha=1.0):\n    if alpha <= 0:\n        return x, y, y, 1.0\n    lam = np.random.beta(alpha, alpha)\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(device)\n    y_a, y_b = y, y[index]\n    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n    # adjust lambda to the exact area ratio\n    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n    return x, y_a, y_b, lam\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:37:09.290853Z","iopub.execute_input":"2025-11-17T04:37:09.291312Z","iopub.status.idle":"2025-11-17T04:37:09.298732Z","shell.execute_reply.started":"2025-11-17T04:37:09.291295Z","shell.execute_reply":"2025-11-17T04:37:09.297836Z"}},"outputs":[],"execution_count":31},{"id":"d40b1db3-1e05-4180-aae9-5de3dc68ac16","cell_type":"code","source":"scaler = torch.amp.GradScaler(device='cuda')\nbest_acc = 0.0\n\ncheckpoint = torch.load(\"/kaggle/input/model-checkpoint/model_vit_epoch_8.pth\", map_location=device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nscheduler.load_state_dict(checkpoint['scheduler_state_dict'])\nscaler.load_state_dict(checkpoint['scaler_state_dict'])\n\nstart_epoch = checkpoint['epoch'] + 1\nprint(\"Checkpoint loaded. Continue from epoch:\", start_epoch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:40:27.681591Z","iopub.execute_input":"2025-11-17T04:40:27.682325Z","iopub.status.idle":"2025-11-17T04:40:28.109157Z","shell.execute_reply.started":"2025-11-17T04:40:27.682284Z","shell.execute_reply":"2025-11-17T04:40:28.108431Z"}},"outputs":[{"name":"stdout","text":"Checkpoint loaded. Continue from epoch: 9\n","output_type":"stream"}],"execution_count":37},{"id":"5d2af6ec-c88e-42c3-9f61-d208c40564b0","cell_type":"code","source":"print(\"Starting training...\\n\")\n\nfor epoch in range(start_epoch, total_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    loop = tqdm(trainloader, desc=f\"Training Epoch {epoch + 1}\", leave=False)\n\n    for inputs, targets in loop:\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        # Randomly apply mixup or cutmix\n        do_mix = random.random() < mixup_prob\n        if do_mix:\n            if random.random() < 0.5:\n                inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha=mixup_alpha)\n            else:\n                inputs, targets_a, targets_b, lam = cutmix_data(inputs, targets, alpha=cutmix_alpha)\n        else:\n            targets_a, targets_b, lam = targets, targets, 1.0\n\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n            outputs = model(inputs)\n            if lam != 1.0:\n                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n            else:\n                loss = criterion(outputs, targets)\n\n        scaler.scale(loss).backward()\n        # gradient clipping helps stability\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.detach(), 1)\n        \n        total_train += targets.size(0)\n        \n        correct_train += (predicted == targets).sum().item()\n\n        loop.set_postfix(loss=loss.item())\n\n    # scheduler step per epoch\n    scheduler.step()\n\n    train_accuracy = 100. * correct_train / total_train\n    avg_loss = running_loss / len(trainloader)\n    print(f\"Epoch {epoch+1}: Train Loss = {avg_loss:.4f}, Accuracy = {train_accuracy:.2f}%\")\n\n    # -------- validation --------\n    model.eval()\n    correct_test = 0\n    total_test = 0\n    with torch.no_grad():\n        for inputs, targets in tqdm(testloader, desc=f\"Testing Epoch {epoch + 1}\", leave=False):\n            inputs, targets = inputs.to(device), targets.to(device)\n            with torch.amp.autocast(device_type='cuda'):\n                outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total_test += targets.size(0)\n            correct_test += predicted.eq(targets).sum().item()\n\n    test_accuracy = 100. * correct_test / total_test\n    print(f\"Test Accuracy after Epoch {epoch + 1}: {test_accuracy:.2f}%\")\n\n    # save best\n    if test_accuracy > best_acc:\n        best_acc = test_accuracy\n        print(f\"Best model saved with accuracy: {best_acc:.2f}%\")\n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'scaler_state_dict': scaler.state_dict(),\n            'rng_state': torch.get_rng_state(),\n        }\n        torch.save(checkpoint, f'model_vit_epoch_{epoch}.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:40:28.247864Z","iopub.execute_input":"2025-11-17T04:40:28.248454Z","iopub.status.idle":"2025-11-17T08:02:21.937369Z","shell.execute_reply.started":"2025-11-17T04:40:28.248434Z","shell.execute_reply":"2025-11-17T08:02:21.936264Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10:   0%|          | 0/2368 [00:00<?, ?it/s]/tmp/ipykernel_48/3488519781.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss = 1.8501, Accuracy = 68.61%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 10: 85.60%\nBest model saved with accuracy: 85.60%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss = 1.8065, Accuracy = 68.96%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 11: 85.79%\nBest model saved with accuracy: 85.79%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss = 1.7768, Accuracy = 71.07%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 12: 85.88%\nBest model saved with accuracy: 85.88%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss = 1.7847, Accuracy = 69.96%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 13: 85.87%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss = 1.7176, Accuracy = 71.72%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 14: 86.21%\nBest model saved with accuracy: 86.21%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss = 1.6904, Accuracy = 72.51%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 15: 86.00%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Train Loss = 1.6888, Accuracy = 72.10%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 16: 86.40%\nBest model saved with accuracy: 86.40%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Train Loss = 1.6595, Accuracy = 73.99%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 17: 86.29%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Train Loss = 1.6427, Accuracy = 74.19%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 18: 86.36%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Train Loss = 1.6440, Accuracy = 74.26%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 19: 86.17%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Train Loss = 1.6373, Accuracy = 73.78%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 20: 86.18%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Train Loss = 1.5746, Accuracy = 76.66%\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Test Accuracy after Epoch 21: 86.30%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/3488519781.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":38},{"id":"ef11b950-7288-424e-a93f-8a49cf972ce1","cell_type":"code","source":"torch.save(model.state_dict(), f'vit_food_101.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T08:16:30.460583Z","iopub.execute_input":"2025-11-17T08:16:30.461357Z","iopub.status.idle":"2025-11-17T08:16:30.921084Z","shell.execute_reply.started":"2025-11-17T08:16:30.461333Z","shell.execute_reply":"2025-11-17T08:16:30.920237Z"}},"outputs":[],"execution_count":40},{"id":"c23c8097-56cf-4d7a-aa3e-de3693b1bbaa","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}